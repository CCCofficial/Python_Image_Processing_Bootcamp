{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Week6_Classify.ipynb","provenance":[],"collapsed_sections":["O6WCOlTNM6D6","VA4x4OY8NEoC","Am7H8UM4NYQZ","_HYeChjKM8Ib","pu4nesClNrrL","gqcFUv-XNw3Z","GIMTolvHN2mB","dg5U64w7N63j"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Reading and Viewing Material"],"metadata":{"id":"O6WCOlTNM6D6"}},{"cell_type":"markdown","source":["In this exercise we will be classifying 9 classes of plankton. First here is some reading and viewing references that cover many of the topics we will be doing.\n","\n","**Erosion**\n","\n","https://towardsdatascience.com/introduction-to-image-processing-with-python-dilation-and-erosion-for-beginners-d3a0f29ad72b\n","\n","**Classifiers**\n","\n","https://www.simplilearn.com/tutorials/machine-learning-tutorial/classification-in-machine-learning\n","https://www.edureka.co/blog/classification-algorithms/\n","https://www.tutorialspoint.com/machine_learning_with_python/classification_introduction.htm\n","https://towardsdatascience.com/machine-learning-classifiers-a5cc4e1b0623\n","https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html?highlight=standardscaler\n","\n","**Nearest Neighbor** \n","https://youtu.be/HVXime0nQeI\n","\n","**SVM**\n","https://youtu.be/efR1C6CvhmE\n","https://youtu.be/8A7L0GsBiLQ\n","\n","**Random Forest**\n","https://youtu.be/J4Wdy0Wc_xQ\n","\n","**Linear Discriminant Analysis**\n","https://youtu.be/azXCzI57Yfc\n","\n","**Train and Test Sets**\n","https://youtu.be/EuBBz3bI-aA\n","\n","**Scaling**\n","https://youtu.be/SzZ6GpcfoQY\n","https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n","\n","**Accuracy and Confusion Matrix**\n","\n","https://youtu.be/Kdsp6soqA7o\n","https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n","https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea\n"],"metadata":{"id":"j9LHA5DPMGW7"}},{"cell_type":"markdown","source":["# Installing and Importing Libraries"],"metadata":{"id":"VA4x4OY8NEoC"}},{"cell_type":"markdown","source":["Install the mahotas library so we can import Zernike Moments, to extract shape features."],"metadata":{"id":"SWhLRXFmBAKk"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSmexSH98qoW"},"outputs":[],"source":["!pip install mahotas"]},{"cell_type":"markdown","source":["Import all the libraries we will need. The os libraries let us load files from the drive. The sklearn files are for performing classification. The seaborn library is for plotting the confusion matrix."],"metadata":{"id":"ZwvNjddABOpz"}},{"cell_type":"code","source":["import numpy as np\n","import cv2\n","import os\n","import matplotlib.pyplot as plt\n","from mahotas.zernike import zernike_moments\n","from google.colab.patches import cv2_imshow\n","from IPython import display\n","from google.colab import drive\n","\n","from os import listdir\n","from os.path import isfile, join\n","from mahotas.zernike import zernike_moments\n","\n","from sklearn import preprocessing\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","\n","import time\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.svm import SVC\n","import seaborn as sn"],"metadata":{"id":"ioyhL5CH9Ufq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mount the Drive"],"metadata":{"id":"Am7H8UM4NYQZ"}},{"cell_type":"markdown","source":["Mount the drive and create pointers to the test and train file directories."],"metadata":{"id":"xJONkNdGBloc"}},{"cell_type":"code","source":["drive.mount('/content/drive')\n","TRAIN_DIR = r'/content/drive/MyDrive/SCIP_DATA/Images/TRAIN_IMAGEBIN2'\n","TEST_DIR = r'/content/drive/MyDrive/SCIP_DATA/Images/TEST_IMAGEBIN2'"],"metadata":{"id":"FpJnRlCM8uZz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Extracting Features from Image and Contour List"],"metadata":{"id":"_HYeChjKM8Ib"}},{"cell_type":"markdown","source":["Create a function that collects 43 features from a binary image and the contours of the binary image. We will use this function to get features of the training and test images."],"metadata":{"id":"631YHhwVBrfp"}},{"cell_type":"code","source":["def getFeatures(binaryIM,objContour):\n","    feat=[]\n","    \n","    area = cv2.contourArea(objContour)\n","    feat.append(area)\n","    \n","    # aspect ratio\n","    ((x0,y0),(w,h),theta) = cv2.minAreaRect(objContour)  # from https://www.programcreek.com/python/example/89463/cv2.minAreaRect \n","    if w==0 or h==0:\n","        aspectRatio=0\n","    elif w>=h:\n","        aspectRatio = float(w)/h\n","    else:\n","        aspectRatio = float(h)/w\n","    feat.append(aspectRatio)\n","\n","    # solidity\n","    hull = cv2.convexHull(objContour)    \n","    hull_area = cv2.contourArea(hull)\n","    solidity = float(area)/hull_area\n","    feat.append(hull_area)\n","    feat.append(solidity)\n","\n","    # ellipse\n","    (xe,ye),(eMajor,eMinor),angle = cv2.fitEllipse(objContour)\n","    feat.append(eMajor)\n","    feat.append(eMinor)\n","\n","    # contour\n","    contourLen=len(objContour)   \n","    mean = np.mean(objContour)\n","    std = np.std(objContour)\n","    perimeter = cv2.arcLength(objContour,True)\n","    feat.append(contourLen)\n","    feat.append(mean)\n","    feat.append(std)\n","    feat.append(perimeter)\n","\n","    # circle\n","    (xc,yc),radius = cv2.minEnclosingCircle(objContour)\n","    feat.append(radius)\n","\n","    # ZERNIKE MOMENTS\n","    W, H = binaryIM.shape\n","    R = min(W, H) / 2\n","    zer = zernike_moments(binaryIM, R, 8)\n","    zsum=np.sum(zer[1:])\n","    zer[0]=zsum           # first Zernike moment always constant so replace with sum\n","    for z in zer:\n","        feat.append(z)\n","\n","    \n","    # HARALICK FEATURES\n","    mom = cv2.HuMoments(cv2.moments(binaryIM)).flatten()\n","    momLog=abs(np.log10(np.abs(mom))) # get absolute value of log\n","    momLog=(1000*momLog).astype(int)\n","    for m in momLog:\n","        feat.append(m)\n","\n","    maxFeat=43\n","    featVector=np.zeros((1,maxFeat))\n","    featVector[0]=feat\n","    return(featVector)"],"metadata":{"id":"UprHVfQp8uk7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create List of Class Names"],"metadata":{"id":"pu4nesClNrrL"}},{"cell_type":"markdown","source":["Create a label of the classes of images. Each image starts with the class name. We will extract the first three letters of each image as the class. The className list will save the class names. There should be 9 unique class names."],"metadata":{"id":"1HLRnqrEB7jq"}},{"cell_type":"code","source":["############## Create classes from file name ##############\n","files = [f for f in listdir(TRAIN_DIR) if isfile(join(TRAIN_DIR, f))]\n","className=[]\n","for file in files:\n","    n=file[0:3]\n","    if n not in className:\n","        className.append(n)\n","  "],"metadata":{"id":"ohoRXGAk8us7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's veryify we captured the 9 unique class names."],"metadata":{"id":"-7xL1wUnCPO8"}},{"cell_type":"code","source":["print(className)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AoOGgQJj8uwc","executionInfo":{"status":"ok","timestamp":1657034823525,"user_tz":420,"elapsed":137,"user":{"displayName":"Tom Z","userId":"08906810142490329583"}},"outputId":"1d041db0-0951-4121-b46c-e233a4526d4a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['spi', 'ste', 'vol', 'did', 'dil', 'par', 'ble', 'arc', 'act']\n"]}]},{"cell_type":"markdown","source":["# Create Training Set"],"metadata":{"id":"gqcFUv-XNw3Z"}},{"cell_type":"markdown","source":["Now we are ready to get the features for each image in the training set. We start with binary images, produced by applying a threshould to the greyscale images. I already did this since we performed this in a previous class. Notice I am using an erosion function (cv2.erode) since some of the objects are \"attached\" to other objects during the detection. "],"metadata":{"id":"xNBqVTLwCXWS"}},{"cell_type":"code","source":["############## Get features of training set ##############\n","DIR=TRAIN_DIR\n","maxFeat=43\n","files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n","xTrain=np.zeros((1,maxFeat))\n","yTrain=np.zeros((1))\n","kernel = np.ones((5, 5), np.uint8)\n","for file in files:\n","    binaryIM=cv2.imread(DIR+'/'+file,cv2.IMREAD_GRAYSCALE)\n","    binaryIM = cv2.erode(binaryIM, kernel)\n","    binaryIM = cv2.erode(binaryIM, kernel)\n","    contours, hierarchy = cv2.findContours(binaryIM, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # all countour points, uses more memory\n","    i=0\n","    maxArea=0\n","    bestCnt=-1\n","    for cnt in contours:\n","        area = cv2.contourArea(cnt)\n","        if area>maxArea:\n","            maxArea=area\n","            bestCnt=i\n","        i+=1\n","    if area>0 and bestCnt!=-1 and len(contours[bestCnt])>4: # ellipse requires at least 5 points\n","        (r,c)=binaryIM.shape\n","        im=np.zeros((r,c))\n","        # Draw all contours, -1 signifies drawing all contours\n","        feat=getFeatures(binaryIM,contours[bestCnt])\n","        xTrain=np.append(xTrain,feat,axis=0)\n","        nameIndex=className.index(file[0:3])\n","        yTrain=np.append(yTrain,nameIndex)\n","xTrain=np.delete(xTrain,0,0) # eliminate first row which contains all zeros\n","yTrain=np.delete(yTrain,0,0) # eliminate first row which contains all zeros\n"],"metadata":{"id":"7_ZU5sD28uzy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's check that we extracted features from 3954 training images. Notice the xTrain array has two dimensions, 43 features for each of the 3954 images. The yTrain has one dimension, the class, from 0 to 8, for each of the 3954 images."],"metadata":{"id":"rj0UWeG3C9bC"}},{"cell_type":"code","source":["print(xTrain.shape)\n","print(yTrain.shape)"],"metadata":{"id":"l-sGtQ7c_5lk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create Testing Set"],"metadata":{"id":"GIMTolvHN2mB"}},{"cell_type":"code","source":["############## Get features of test set ##############\n","DIR=TEST_DIR\n","maxFeat=43\n","files = [f for f in listdir(DIR) if isfile(join(DIR, f))]\n","xTest=np.zeros((1,maxFeat))\n","yTest=np.zeros((1))\n","kernel = np.ones((5, 5), np.uint8)\n","for file in files:\n","    binaryIM=cv2.imread(DIR+'/'+file,cv2.IMREAD_GRAYSCALE)\n","    binaryIM = cv2.erode(binaryIM, kernel)\n","    binaryIM = cv2.erode(binaryIM, kernel)\n","    contours, hierarchy = cv2.findContours(binaryIM, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # all countour points, uses more memory\n","    i=0\n","    maxArea=0\n","    bestCnt=-1\n","    for cnt in contours:\n","        area = cv2.contourArea(cnt)\n","        if area>maxArea:\n","            maxArea=area\n","            bestCnt=i\n","        i+=1\n","    if area>0 and bestCnt!=-1 and len(contours[bestCnt])>4: # ellipse requires at least 5 points\n","        (r,c)=binaryIM.shape\n","        im=np.zeros((r,c))\n","        # Draw all contours, -1 signifies drawing all contours\n","        feat=getFeatures(binaryIM,contours[bestCnt])\n","        xTest=np.append(xTest,feat,axis=0)\n","        nameIndex=className.index(file[0:3])\n","        yTest=np.append(yTest,nameIndex)\n","xTest=np.delete(xTest,0,0) # eliminate first row which contains all zeros\n","yTest=np.delete(yTest,0,0) # eliminate first row which contains all zeros"],"metadata":{"id":"LvCWPMuf_09L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's check that we extracted features from 1106 training images. Notice the xTest array has two dimensions, 43 features for each of the 1106 images. The yTest has one dimension, the class, from 0 to 8, for each of the 1106 images."],"metadata":{"id":"XpGJmEW9D3_S"}},{"cell_type":"code","source":["print(xTest.shape)\n","print(yTest.shape)"],"metadata":{"id":"kvX962g6A2Cq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The features have all kind of values, from small fractions to large integers. This sometimes confuses classifiers. To make the numbers all in a similar range, we scale the features so the mean (average) for each feature is 0 and the standard deviation is one. "],"metadata":{"id":"M2itshjPEPT5"}},{"cell_type":"code","source":["######################## Scale Features ###############################\n","xTest = preprocessing.StandardScaler().fit_transform(xTest)\n","xTrain = preprocessing.StandardScaler().fit_transform(xTrain)"],"metadata":{"id":"mxl8KSOcAhVe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Classify Testing Images and Plot Confusion Matrix"],"metadata":{"id":"dg5U64w7N63j"}},{"cell_type":"markdown","source":["With all our features extracted and scaled for our training and testing set, we are now ready to train four classifiers. We will also time the training and testing of each classifier and use it, along with accuracy, to evaluate the performance of each classifer. Time is imporant if you want a fast responsive system, like auto-driving a car. We will also create a confusion matrix for each classifer to see what classes cause the classifiers to make mistakes.  "],"metadata":{"id":"ChXD-vLtE3rh"}},{"cell_type":"code","source":["######################## Classify #####################################\n","classifiers = [\n","    SVC(gamma='auto'),\n","    KNeighborsClassifier(3),\n","    RandomForestClassifier(),\n","    LinearDiscriminantAnalysis()\n","    ]\n","\n","for clf in classifiers:\n","    T1=time.time()\n","    clf.fit(xTrain, yTrain)\n","    name = clf.__class__.__name__\n","    T2=time.time()\n","    yPredict = clf.predict(xTest)\n","    T3=time.time()\n","    acc = accuracy_score(yTest, yPredict)\n","    tTrain=round((T2-T1)*1000,0)\n","    tPredict=round((T3-T2)*1000,0)\n","    print(name,'Accuracy:',round(acc,2),'%','Train:',int(tTrain),'msec','Predict:',int(tPredict),'msec')\n","    \n","    # create normalize confusion matrix\n","    cm=confusion_matrix(yPredict,yTest)  \n","    cmNorm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","    cmNorm = cmNorm.round(decimals=2)\n","    ax=sn.heatmap(cmNorm,annot=True,xticklabels=className,yticklabels=className)\n","    plt.title(name)\n","    plt.xlabel('True Label')\n","    plt.ylabel('Predicted Label')\n","    plt.show()"],"metadata":{"id":"Sc7Z4o55Ai7O"},"execution_count":null,"outputs":[]}]}