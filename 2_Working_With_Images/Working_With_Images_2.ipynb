{"cells":[{"cell_type":"markdown","metadata":{"id":"xWkgRqz3eUpi"},"source":["# Matplotlib and Numpy and OpenCV Fundamentals for Image Processing\n","\n"]},{"cell_type":"markdown","source":["# Table of Contents (With Clickable Links!)\n","1.   [Image Visualization & Numpy Array Slicing & Image Manipulation](#section1)\n","2.   [Rotating an Image in Python using OpenCV](#section3)\n","3.   [Inverting an Image](#section4)\n","4.   [Cropping an Image](#section5)\n","5.   [Inserting a Cropped Image into an Image](#section6)\n","6.   [Inserting a Rotated Cropped Image](#section7)\n","---\n","\n","\n"],"metadata":{"id":"Wd8LHIAPbvd4"}},{"cell_type":"markdown","source":["This Section loads essential dependences for image processing:\n","**numpy**, **pandas**, **cv2**, **skimage**, **PIL**, **matplotlib**\n","\n","*   [Numpy](https://www.numpy.org/) is an array manipulation library, used for linear algebra, Fourier transform, and random number capabilities.\n","*   [Pandas](https://pandas.pydata.org/) is a library for data manipulation and data analysis.\n","*   [CV2](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html) is a library for computer vision tasks.\n","*   [Skimage](https://scikit-image.org/) is a library which supports image processing applications on python.\n","*   [Matplotlib](https://matplotlib.org/) is a library which generates figures and provides graphical user interface toolkit..\n"],"metadata":{"id":"gyE_UoriMDsR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jVbM3iveUpp"},"outputs":[],"source":["from google.colab.patches import cv2_imshow  #this is a specific patch developed by google colab to display images\n","import numpy as np\n","import pandas as pd\n","import cv2\n","from skimage import io\n","from PIL import Image \n","import matplotlib.pyplot as plt\n","import time\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"IVWNQpAjeUpr"},"source":["## Image Visualization & Numpy Array Slicing<a name=\"section1\"></a>\n","We will use an image from Studio Ghilbi called Totoro.This section shows how pull images from the internet into a colab notebook. An image is a collection of pixels, which is abbreviation for picture elements. A grayscale image can be represented as a two dimensional array, whose first axis corresponds to the x coordinate of the image and the second axis corresponds to the y coordinate.   The array is a coordinate pair (x,y).  There are restrictions on these arrays for images. The value is restricted from 0 to 255 (called an unsigned 8 bit integer - uint8 datatype).  A value of 0 is black and 255 is white for that pixel.  The value specifies the level of grayness.  For RGB images, the image is a three dimensional array.  The third axis is for the red, green, and blue components of each pixel, called channels.  For each of these color channels, there is a value between between 0 and 255. The combinations of different values for the three components red, green, and blue can result in at least 16.7 million colors. A color image is the sum of these color channel projected onto the a 2D screen (x,y coordinates are the position) .  Since images can be represented as multidimensional arrays, and we will explore these in this section. \n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"4AMlfFa7eUpr","executionInfo":{"status":"error","timestamp":1666387207117,"user_tz":420,"elapsed":675,"user":{"displayName":"esquerra@sfsu.edu","userId":"15444472133678738227"}},"outputId":"4fdc3516-fad3-4929-e51f-d6a520e65f05","colab":{"base_uri":"https://localhost:8080/","height":236}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-497acda28add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'curl -O https://studioghiblimovies.com/wp-content/uploads/2014/11/totoro.jpg'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#this allows you to import any image from the internet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'totoro.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data shape:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"the resolution is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pixels'\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;31m#a pictures resolution is the total number of pixels, x-total times y-total\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data type:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#type(data[1,1,1]) specifies the data type for each element in the array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}],"source":["import os\n","os.system('curl -O https://studioghiblimovies.com/wp-content/uploads/2014/11/totoro.jpg')  #this allows you to import any image from the internet\n","data=plt.imread('totoro.jpg')\n","print('Data shape:',data.shape, \"the resolution is\", data.shape[0]*data.shape[1], 'pixels' ) #a pictures resolution is the total number of pixels, x-total times y-total\n","print('Data type:',type(data), type(data[1,1,1])) #type(data[1,1,1]) specifies the data type for each element in the array"]},{"cell_type":"markdown","metadata":{"id":"XjHtzwiNeUps"},"source":["This image has 3 [RGB channels](https://en.wikipedia.org/wiki/Channel_(digital_image)#RGB). Other color image formats exist, but for this module we will use RGB and GreyScale.  Let's visualize the image using matplotlib.pyplot.imshow and cv2_imshow. Note: cv2.imshow does not work in Colab but the patch, cv2_imshow does (with limited flexibility). CLICK on the {x} icon on the left side of your CoLab browser to see the variables.  What is listed under Name, Type and Shape?  Does this match with the values given by the code above?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5hzImdGieUpt"},"outputs":[],"source":["#NOTE:  In the display window there is a slider to move down and up\n","plt. figure(figsize = (20,20))  #this is way to adjust the image size in plotting\n","plt.imshow(data)\n","plt.show()\n","cv2_imshow(data)  \n","#Note within the display window below you can click on the display window and scrool with the slider"]},{"cell_type":"markdown","source":["Notice anything different about the images?  \n","Image ploting (and most saved images, just as JPEGs) in Matplotlib follows the convention that the order of the arrays in 3D is RGB--image_array[0]=red pixels; image_array[1]=green_pixels; image_array[2]=blue_pixels.  OpenCV follows a different convention in which the order of the color arrays are BGR--- image_array[0]=blue_pixels; image_array[1]=green_pixels; image_array[2]=red_pixels.\n","\n","In this section, you will convert the original 3D image array into a new array that plots the same in cv2_imshow as the original did in plt.imshow()\n"],"metadata":{"id":"ykMMIGwhm3O_"}},{"cell_type":"code","source":["#{STUDENT ACTIVITY} write code to generate a new image called data_BGR where you swamp the red and blue channels\n","# -- see above (or google) to note what (x,y) array in the 3D image corresponds to red and blue\n","# NOTE:  Stacking arrays (making 2D arrays into one 3D array) in np.numpy takes practice  - ADVICE:  let google be your friend and search solutions and documentation\n","data_BGR = np.zeros({data.shape}, dtype='uint8') #METHOD1\n","data_BGR[:,:,0]=data[:,:,{INSERT CODE HERE}]     #METHOD1\n","data_BGR[:,:,1]=data[:,:,{INSERT CODE HERE}]     #METHOD1\n","data_BGR[:,:,2]=data[:,:,{INSERT CODE HERE}]     #METHOD1\n","cv2_imshow(data_BGR)  # #METHOD1 tests result\n","#{STUDENT ACTIVITY} uncomment and write code\n","#data_GBR = np.dstack(({INSERT CODE HERE})) #METHOD2  using np.stack module\n","\n","#{STUDENT ACTIVITY} -- search for a way to use the openCV package to do this in with a built in package\n","#data_GBR =  cv2.cvtColor({INSERT CODE HERE}) #  \n","#cv2_imshow(data_GBR)\n"],"metadata":{"id":"mFeTXVQsmwTG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"2_GIlhfoox2j"}},{"cell_type":"markdown","metadata":{"id":"2Nyjb1_9eUpu"},"source":["In this section, you will break-apart (slice) the image (3D array) into color channels (individual 2D arrays that correspond to the intensity of each color). You will plot a grey-scale image of color channel to make a canvas with (1,N) sub-plots for each image channel by slicing one by one. The intensity of the color is white is most intense (255) and black is least (0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I8xhUOuZeUpv"},"outputs":[],"source":["fig,axes=plt.subplots(1,data.shape[2],figsize=(16,8),facecolor='w')\n","#write the actual for loop to plot each subplot\n","for ch in range({INSERT CODE HERE}): #{student insert code here}\n","    axes[ch].imshow(data[:,:,ch],cmap='gray')\n","plt.show()\n","#{STUDENT EXPLORE}  Look up and explore cmaps, facecolor, and figsize.  Can you plot as column rather than a row?\n"]},{"cell_type":"markdown","source":["In the next section you will write a for loop that displays each color channel in an RGB image with the other color channels zero. For example, you will keep the Red channel numbers equal to image but make the G and B channels zero, and then plot as a color image."],"metadata":{"id":"UwkfosEzkYmK"}},{"cell_type":"code","source":["image = np.copy(data_BGR) # in python = is an assignment operator.  np.copy makes a new instance and new variable.  \n","#Note using np.copy means changing the assigned variable can update all assignments\n","for channel_index in range(3):\n","    channel = np.zeros(shape=image.shape, dtype=np.uint8)\n","    channel[{INSERT CODE HERE}] = image[:,:,channel_index]\n","    cv2_imshow(channel)\n","   "],"metadata":{"id":"NYCGjhRdRnLg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this section you will display the histagram of the color per color channel using the CV2.calcHist method"],"metadata":{"id":"sUKoL79Mjf2W"}},{"cell_type":"code","source":["color = ('b','g','r')\n","image = np.copy(data_BGR)\n","for i,col in enumerate(color):\n","    histr = cv2.calcHist([image],[i],None,[256],[0,256])\n","    plt.plot(histr,color = col)\n","    plt.xlim([0,256])\n","plt.show()"],"metadata":{"id":"PuYuwsnejZvA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SEDqVXXVeUpv"},"source":["In this section you will determine how openCV converts a BRG image to greyscale.  The two options are 1) GreyScaleArray = (Blue_Ch+Green_Ch+Red_Ch+)/3 OR the NISC method, GreyScaleArray = 0.114 ∙ Blue_CH + 0.587 ∙ Green_CH+ +0.299 ∙ Red_CH.  In this section you will write code to compare these to method to the openCV code: grey_CV2 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","{https://docs.opencv.org/4.x/db/d64/tutorial_js_colorspaces.html}\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"83zBaC_6eUpw"},"outputs":[],"source":["grey_avg =  {INSERT CODE HERE} #{write code here} that makes the image greyscale as (R+G+B)/3\n","grey_NISC = {INSERT CODE HERE} #{write code here} that makes the image greyscale as 0.114 ∙ B + 0.587 ∙ G+ +0.299 ∙ R\n","grey_CV2 = cv2.cvtColor({INSERT CODE HERE})\n","#{student code here} use the example of subploting above do a subplot of the 3 methods.  Which on matches the CV2 method?\n","fig,axes=plt.subplots(1,data.shape[2],figsize=(22,11),facecolor='w')\n","axes[0].imshow(grey_avg,cmap='gray')\n","axes[1].imshow(grey_NISC,cmap='gray')\n","axes[2].imshow(grey_CV2,cmap='gray')\n","plt.show()\n","#this maybe hard to tell visually, can you write some code to mathematically compare?\n","print('Difference of average and CV2',np.sum(np.subtract(grey_avg,grey_CV2)))\n","print('Difference of NISC and CV2',np.sum(np.subtract(grey_NISC,grey_CV2)))\n","#the numbers for the smallest absolute value is not zero but one is much smaller than the other.\n","#{STUDENT EXPLORATION} covert and view in HSV color space https://docs.opencv.org/4.x/df/d9d/tutorial_py_colorspaces.html. "]},{"cell_type":"markdown","source":["We will now explore the concept of [thresholding](https://en.wikipedia.org/wiki/Thresholding_(image_processing)).  This turns your image into a binary image (just two possible values). There are functions in OPENCV that automatically do this, but we will explore how this is done to the image array directly. \n"],"metadata":{"id":"azjen5JzrpU2"}},{"cell_type":"code","source":["Image = np.copy(data_BGR)  #creates a copy of the image\n","greyIM = cv2.cvtColor({INSERT CODE HERE}) #converts to grayscale\n","greyIM[greyIM<25] = {INSERT CODE HERE} #replaces all values below 25 to zero\n","greyIM[greyIM>25] = {INSERT CODE HERE} #replaces all values above 25 to 255\n","cv2_imshow(greyIM)\n","\n"],"metadata":{"id":"eJhxBuPs9Scw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#{STUDENT EXPLORATION} Play with the threshold values (25 in example)\n","#{STUDENT EXPLORATION} Does the white and black need to be the same?\n","#{STUDENT EXPLORATION} How does this look with the full color image? \n","#{STUDENT EXCERCISE} Modify the code to make the outline white on a black background -- this is called inverting the image\n","#{STUDENT EXPLORATION} Play with the threshold values in th\n","IIM = np.copy(greyIM)\n","{INSERT CODE HERE} = 254   #why is this not 255, can you add a line to make it 255 later?\n","{INSERT CODE HERE}= 0\n","cv2_imshow(IIM)"],"metadata":{"id":"vr8cA8pX9SVo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Find image contour of the grayscale image\n","Method 1: Use the matplotlib. contour\n","\n","More Info: [matplotlib contour](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.contour.html)"],"metadata":{"id":"u7SoNlixwbvL"}},{"cell_type":"code","source":["plt.contour(greyIM,origin = \"image\")\n","#{STUDENT EXPLORATION} what is the reason for having the origin in the function?"],"metadata":{"id":"ugSW7x5g9SG4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Method 2: Use the openCV lib\n","\n","More info: [Contour](https://docs.opencv.org/3.1.0/d4/d73/tutorial_py_contours_begin.html)"],"metadata":{"id":"0By6qBSj3VYO"}},{"cell_type":"code","source":["# Set threshold for the countour detection\n","test = np.copy(data_BGR)\n","ret, thresh = cv2.threshold(greyIM,150,255,0)\n","contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n","cv2.drawContours(test, contours, -1, (0,255,0), 3)\n","plt.imshow(test)\n","#{STUDENT EXPLORATION} play around and explore the values at points -1, (0,255,0), 3.  What do these do?\n","#{STUDENT EXERCISE} Print the countour on a black background\n","test2 = np.zeros(data.shape, dtype='uint8')\n","cv2.drawContours({INSERT CODE HERE})\n","plt.imshow(test2)"],"metadata":{"id":"pSZrY7x93CWE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","## Rotating an Image in Python using OpenCV <a name=\"section3\"></a>\n","\n","We can rotate the image using matrix manipulation by creating an empty image with np.zeroes() and swapping indexes so that the order that you read the pixels will allow you to perform some basic rotations. \n","\n","Assignment: Try performing this with grayscale image. \n","\n","\n","Here we use a method called cv2.rotate() which consists of the following:\n","\n","**Syntax:** cv2.rotate(src, rotateCode[, dst])\n","\n","**Parameters:**\n","\n","\n","src: Is the image you will use\n","\n","\n","rotateCode: Will specify how to rotate the array. Here you can use cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180 or cv2.ROTATE_90_COUNTERCLOCKWISE based on how you want to rotate the image. \n","\n","\n","dst: Is the output image of the same size and depth as src image. This is an optional parameter.\n","\n","\n","**Return Value:** It returns an image."],"metadata":{"id":"p11mfcc7eOw9"}},{"cell_type":"code","source":["#Using matrix array you can create an empty image with np.zeros() and then read the pixels from your current image to \n","#the empty image. You can change the order that you read the pixels to perform some basic rotations. \n","\n","#The following example rotates the image 180 degress: \n","\n","# Using the same totoro image as before we set data to our image\n","# data=plt.imread('totoro.jpg') \n","\n","h,w,c = data.shape\n","\n","empty_img = np.zeros([h,w,c], dtype=np.uint8)\n","\n","print(\"Rotate by 180 degress using matrix manipluation\")\n","\n","for i in range(h):\n","    for j in {INSERT CODE HERE}:\n","        empty_img[i,j] = data[h-i-1,w-j-1]\n","        empty_img = empty_img[0:h,{INSERT CODE HERE}]\n","\n","cv2.imwrite(\"tester1.png\", empty_img)\n","cv2_imshow(empty_img)\n","\n","# You can also use built in tools like cv2.rotate() method to rotate Images\n","  \n","# Using cv2.rotate() method\n","# Using cv2.ROTATE_90_CLOCKWISE rotate\n","# by 90 degrees clockwise\n","image90 = cv2.rotate(data, {INSERT CODE HERE})\n","\n","# 180 degrees clockwise\n","image180 = cv2.rotate(data, {INSERT CODE HERE})\n","\n","# rotate by 270 degrees clockwise\n","image270 = cv2.rotate(data, {INSERT CODE HERE})\n","\n","# Displaying the image\n","cv2_imshow(image90)\n","#cv2_imshow(image180)\n","#cv2_imshow(image270)\n","cv2.waitKey(0)"],"metadata":{"id":"x9EwdGvkfGxA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this section we will take a mirror image of the image.  This can be accomplished with for_loops but we will use the shorthand method of [::-1] which reverses the postions in an array (what was first is last and vice versa).  Since the top becomes the bottom, we will need to rotate 180 degrees."],"metadata":{"id":"70ddhs5DBa4D"}},{"cell_type":"code","source":["\n","print(\"Mirror image matrix manipluation\")\n","\n","MirrorIM = cv2.rotate(data_BGR[::-1], cv2.ROTATE_180)\n","cv2_imshow(MirrorIM)"],"metadata":{"id":"LRfw5D2pxPmv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","## Inverting an Image <a name=\"section4\"></a>\n","\n","Images are represented using RGB or Red Green Blue values and inverting an image means reversing the colors on the image. For example, the inverted color for red color will be (0, 255, 255). Note that 0 became 255 and 255 became 0. This means that inverting an image is essentially subtracting the old RGB values from 255. New_Value = 255 - old_value. \n","\n","We can invert an image using two methods either Open CV or Numpy. With OpenCV we use **bitwise_not()**  and with Numpy we use **numpy.invert()**. \n","\n","In the following example an Image is loaded, inverted and saved in local directory and finally displayed along with original image for comparison. "],"metadata":{"id":"e5lGWss5nARp"}},{"cell_type":"code","source":["#load same totoro Image as before\n","image = cv2.imread(\"totoro.jpg\")\n","\n","#Invert using OpenCV using cv2.bitwise_not() which takes the loaded image as it input arugment \n","inverted_imageCV = cv2.bitwise_not(image)\n","\n","#save the image to disk as inverted.jpg\n","cv2.imwrite(\"inverted.jpg\", inverted_imageCV)\n","\n","#Display orginal and inverted Image\n","print(\"Original Image\")\n","cv2_imshow(image)\n","print(\"Inverted Image using OpenCV\")\n","cv2_imshow(inverted_imageCV)\n","\n","#Invert using numpy using np.invert() which takes the loaded image as it input arugment \n","inverted_imageNP = np.invert({INSERT CODE HERE})\n","cv2.imwrite(\"inverted.jpg\", inverted_imageNP)\n","print(\"Inverted Image using Numpy\")\n","cv2_imshow(inverted_imageNP)"],"metadata":{"id":"oPlNWU8Yn4Lk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Cropping an Image <a name=\"section5\"></a>\n","\n","Learning Outcomes for this Section:\n","*   Array Slicing\n","*   Indexing and Pixel Coordinates\n","*   Using Array Slicing to Crop an Image\n","\n","Somtimes when dealing with images, we want to crop on a specific region of interest.\n","\n","First, we have the original image as a plot:"],"metadata":{"id":"rLKICJcZr5am"}},{"cell_type":"code","source":["plt.figure()\n","plt.imshow(data)\n","plt.show()"],"metadata":{"id":"VgZjmoKu1Gb8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note how the x- and y-axis has the pixel coordinates, we're going to need that later. The x-axis are the columns and the y-axis are the rows.\n","\n","What if we wanted to only see the white little creature on top of Totoro's head (Totoro is the big furry creature with the whiskers). Here is a sample image cropped image, the code only displays the sample."],"metadata":{"id":"tw77kT341b1z"}},{"cell_type":"code","source":["crop_sample = plt.imread(\"totoro_crop.png\")\n","crop_sample = cv2.cvtColor(crop_sample, cv2.COLOR_BGR2RGB)\n","plt.imshow(crop_sample)\n","plt.show()"],"metadata":{"id":"Trs0tXju7uaS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Your exercise is to use array slicing to crop to the white little creature. It doesn't need to be exact, it's okay to have some of Totoro's head in there.\n","\n","So how do you use array slicing to crop the image? A hint: recall that array slicing follows the format of \"**start coordinate** : **end coordinate**\" for each \"axis\"."],"metadata":{"id":"eOYmg7RGBcsq"}},{"cell_type":"code","source":["# Array Slice Example\n","\n","# Create a sample numpy array using a list\n","# In math terms, this is a vector (ignore this if you don't know what I'm talking about)\n","array_a = np.array([1, 2, 3, 4, 5])\n","\n","# Let's slice the array so that we only get the 2 and 3\n","# Hints: index starts at zero, and the end value is not included\n","array_slice = array_a[1:3]\n","\n","array_slice\n","\n","# We got the 2 and 3, or cropped to the 2 and 3."],"metadata":{"id":"ARGIZOXGE25B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Another hint: recall that array access is by row, column, channel. Only the row and column are needed for this section. Let's go from a single row to multiple rows, creating a matrix (very similar to how an image matrix works)."],"metadata":{"id":"8_WZgkDWE5cQ"}},{"cell_type":"code","source":["# Matrix Slice Example\n","\n","# Create a sample numpy array using a list of lists\n","# To help me visualize it, I see it as rows and columns\n","# Notice the extra square brackets\n","\n","array_b = np.array([[1, 2, 3],\n","                   [4, 5, 6],\n","                   [7, 8, 9]])\n","\n","array_b\n","# Show the array\n","# Note: This is a simplified version of the pixel coordinates of an image"],"metadata":{"id":"Dber4B98FaFB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice how the output looks similar to an Excel sheet with rows and columns. That is how we will access specific elements. Row **0** has **1, 2, 3** and Column **0** has **1, 4, 7**. Remember, indexing starts at 0.\n","\n","Let's slice the array so we only get the bottom left 4 numbers, or the 4, 5, 7, and 8. You can imagine it as a \"crop\" box, if you will. You will need four locations: where the row starts and ends, and where the column starts and ends.\n","\n","The row starts at the middle (look at the 4), so row 1 (index starts at 0). The row ends at the bottom (look at the 7), so row 2. Now for the columns, where does it start and end? The column starts on the left (look at the 4 and 7), so column 0. The column ends on the middle (look at the 5 and 8), so column 1. In summary, the row slicing would be row_start:row_end, or **1:2**. And then column slicing would be column_start:column_end, or **0:1**.\n","\n","Keep in mind, Python does not include the end value. Let's see the example:"],"metadata":{"id":"uVpFrImnKd6R"}},{"cell_type":"code","source":["# Let's slice the array so that we only get the 4, 5, 7, 8.\n","\n","# Array slice format: array_b[row_start:row_end+1, column_start:column_end+1]\n","# Since Python doesn't include that end value, so add 1 to include the end value you want.\n","\n","array_b_slice = array_b[1:3, 0:2]\n","\n","array_b_slice"],"metadata":{"id":"RXxxL4qJKeTg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that you know how to slice an array, now try slicing, or cropping the Totoro image to get that white creature!"],"metadata":{"id":"8r7tPfBIjKlI"}},{"cell_type":"code","source":["# A Solution\n","\n","# Make a copy of original image as a backup:\n","orig_img = data.copy()\n","\n","# Use array slicing\n","# Example: img_array[row_start:row_end, col_start:col_end]\n","crop_img = orig_img[50:150, 350:450]\n","\n","# Show the image\n","plt.imshow(crop_img)\n","plt.show()"],"metadata":{"id":"WqTiPv6ZBdGh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now you know how to use array slicing to crop out an image. The skills you learned move beyond image manipulation, you've learned matrix manipulation skills needed for scientific research!\n","\n","The next skill you will learn is placing that cropped image onto another image."],"metadata":{"id":"3HBpUcy25HEH"}},{"cell_type":"markdown","source":["---\n","# Inserting a Cropped Image into an image <a name=\"section6\"></a>\n","\n","Now that you know how to *fish* out a cropped out image, how about putting that cropped image onto another image? Or maybe even the same image? Like placing the white creature to the right of the blue creature instead.\n","\n","Recall that cropping required knowing where your desired rows and columns ended, also recall that you can get the shape of an image. Let's practice using arrays.\n","\n","First, create array_b, this is similar to the previous section. You can think of this as the big image."],"metadata":{"id":"PaxyAUJejsnO"}},{"cell_type":"code","source":["# Create array_b, same as previous section\n","# You can think of this as the big image\n","array_b = np.array([[1, 2, 3],\n","                    [4, 5, 6],\n","                    [7, 8, 9]])\n","\n","# Show array_b\n","array_b"],"metadata":{"id":"0WIBUzQN1waw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next, create array_c, this will go into array_b. You can think of this as the smaller cropped image."],"metadata":{"id":"VDu8xx-J6bnF"}},{"cell_type":"code","source":["array_c = np.array([[0, 0, 0],\n","                    [0, 0, 0]])\n","\n","# Show array_c\n","array_c"],"metadata":{"id":"EeLWVYTd6xbz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's replace the bottom-right 2 rows of array_b with array_c. First, to avoid the index out of bounds error, we will extract the height and width of the array. If it helps, you can think of height as the number of rows and width as the number of columns."],"metadata":{"id":"0hWN5yZd68b8"}},{"cell_type":"code","source":["# Get the shape of array_c,\n","# then place those two values into height and width variables.\n","# If this were an image, shape would output 3 values.\n","# Use channels for you, if you'd like.\n","height, width = array_c.shape\n","\n","# Print the variables to make sure the shape is correct\n","# Height should be 2, and Width should be 3\n","print(\"height:\", height)\n","print(\"width:\", width)"],"metadata":{"id":"H9vkQ5gH6XPK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we're going to place array_c onto array_b, very similar to how you will do it with an image. To verify the change, let's do a before and after.\n","\n","First, the before:"],"metadata":{"id":"drb0QAds8G_w"}},{"cell_type":"code","source":["print(\"Before:\")\n","array_b"],"metadata":{"id":"x_2AxWve8SpT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now the after. We want to replace the bottom two rows and all the columns. Where does the row start? Column index 1. Where does the column start? Column index 0. Let's use those numbers from array slicing, but now we will replace them!"],"metadata":{"id":"FhWYX4hD9JWU"}},{"cell_type":"code","source":["array_b[1:1+height, 0:0+width] = array_c\n","\n","print(\"After:\")\n","array_b"],"metadata":{"id":"P3pSjOyd81Se"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Notice how I used the height and width variables from the array_c shape, this makes sure that array slice I want to replace has the same dimensions (height and width) as array_c.\n","\n","For the **1+height** part, notice how the 1 is the same as the row start. This is on purpose. Recall that array slicing follows this format:\n","\n","array_b[row_start:row_end, col_start:col_end]\n","\n","So the 1+height is saying, go to start of the row, then stretch to the height. In this case, 2. So 1+2=3. Recall, that Python doesn't include the index 3 row, so this works out. Experiment with different heights and columns to get a feel for things.\n","\n","Now that you know to place a small \"image\" onto a big \"image\" (the arrays you just played with), try it out with the Totoro image. Place the white creature to the right of the blue creature (you don't need to be exact)."],"metadata":{"id":"muaK4eSo9nV1"}},{"cell_type":"code","source":["# Solution:\n","\n","# Make a copy of the original image\n","# Make a copy of original image as a backup:\n","new_img = data.copy()\n","\n","# Get Cropped Image\n","# Use array slicing\n","# Example: img_array[row_start:row_end, col_start:col_end]\n","crop_img = new_img[60:130, 390:450]\n","\n","# Get dimenions of cropped image\n","height, width, ch = crop_img.shape\n","print(\"crop_img.shape:\", crop_img.shape)\n","# Get row start and col start of where you want to place the image (use the plot)\n","row_start = 250\n","col_start = 900\n","\n","# Use array slicing to place cropped image\n","new_img[row_start:row_start+height, col_start:col_start+width] = crop_img\n","\n","# Show the image\n","# Convert to BGR for OpenCV\n","new_img_bgr = cv2.cvtColor(new_img, cv2.COLOR_RGB2BGR)\n","cv2_imshow(new_img_bgr)"],"metadata":{"id":"2xw2vtUi_4GN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Excellent work so far! That was a lot of brain power you had to use, take a break if you need to! Summarizing this section, you just applied array slicing techniques you learned, combined them with shape, and created flexible code. That flexibility is what you will need in your future programming endeavors!\n","\n","Optional section: To really test your skills, try different locations. Also, find out what happens if you try to place the small image outside the index of the big image. What error message do you get?\n","\n","Now that you know how to place a cropped image onto a bigger image (sometimes this is called overlay), what happens if you rotate the cropped image first?"],"metadata":{"id":"VpMZ1KTfDGGl"}},{"cell_type":"code","source":["#{Student Exercise}\n","#insert another object from the image into the original image"],"metadata":{"id":"RY_RrNZ35iH1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","# Inserting a Rotated Cropped Image <a name=\"section7\"></a>\n","\n","So you want to rotate the cropped image first, then place it onto an image? Same rules apply as the previous section, but this time you will have to get the shape after rotating the image. Then everything should be the same from there."],"metadata":{"id":"ssmyOewWe3bt"}},{"cell_type":"code","source":["# Solution\n","\n","# Make a copy of the original image\n","# Make a copy of original image as a backup:\n","new_img = data.copy()\n","\n","# Get Cropped Image\n","# Use array slicing\n","# Example: img_array[row_start:row_end, col_start:col_end]\n","crop_img = new_img[60:130, 390:450]\n","\n","# Rotate the Cropped Image using OpenCV way\n","crop_90 = cv2.rotate(crop_img, cv2.ROTATE_90_CLOCKWISE)\n","\n","# Get dimenions of cropped image\n","height, width, ch = crop_90.shape\n","#print(\"crop_90.shape:\", crop_90.shape)\n","\n","# Get row start and col start of where you want to place the image (use the plot)\n","row_start = 100\n","col_start = 500\n","\n","# Use array slicing to place cropped image\n","new_img[row_start:row_start+height, col_start:col_start+width] = crop_90\n","\n","# Show the image\n","# Convert to BGR for OpenCV\n","new_img_bgr = cv2.cvtColor(new_img, cv2.COLOR_RGB2BGR)\n","cv2_imshow(new_img_bgr)"],"metadata":{"id":"M7bz-nPXr08d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#{STUDENT FUN}  EXPLORE EXPLORE EXPLORE -- modify the code above to see how it works, try on your own images.\n"],"metadata":{"id":"OF5jPIv35tyd"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1yFOsg3VmMH6SjWpOWMaFAS7WoXvLQLar","timestamp":1653873316749},{"file_id":"1NUAI63X4rr5SGTgPqTaBKgtRrW8hzCUD","timestamp":1653434904481},{"file_id":"1UoDhCwR8m7-tPdNp50wcia65_ZE_Iyw1","timestamp":1653414382515},{"file_id":"https://github.com/drinkingkazu/2019-06-17-NeuralNets/blob/master/Preparation%20-%205%20Minutes%20Image%20Data%20in%20Python.ipynb","timestamp":1653371436678}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.12"}},"nbformat":4,"nbformat_minor":0}