{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tracking Primer.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7zdiqgZPqOhO"},"outputs":[],"source":["# Import Libraries For this Notebook\n","import copy\n","import cv2\n","import numpy as np\n","\n","from google.colab.patches import cv2_imshow\n","from IPython import display\n","from time import sleep"]},{"cell_type":"markdown","source":["\n","# Task 1: Make Video of Two Moving Boxes Intersecting\n","\n","Learning Outcomes:\n","* Build programming foundations to creating example videos\n","* Understand the relation to boxes and real life video\n","* Learn how to playback your very own movie\n","\n","You've learned how to make a bouncing sprite and you've learned how to detect objects on a static image. Let's combine both skills for a \"video\" that you will make.\n","\n","So, why boxes again? And how does this relate to object detection? Just like in scientific research, in programming world we use foundational examples to test our understanding of concepts before moving onto more challenging examples. A box is an easy shape for a human (you) and a computer to identify. What about plankton or cells? How would a computer see those organisms? Once you master the box, you will have developed the foundations to take on biological samples. One does not start from the roof when building a house, you start from the foundation.\n","\n","In this lesson, there's a question I want you to think about. When you see two humans walking and crossing each other's paths, you can tell that those are two separate people. But how does a computer see that? Does a computer see two separate people, or one? Keep that question in mind as we move onto the lesson."],"metadata":{"id":"xuq0nUHuXKUD"}},{"cell_type":"markdown","source":["## Single Static Box\n","\n","So you know why we're using boxes and a question about intersecting objects, let's develop a video that has two intersecting boxes. First step, write some code to make a single static image first. Just as we've done before."],"metadata":{"id":"f2Npu9Pmr0fY"}},{"cell_type":"code","source":["# Make a Single Box First\n","\n","\n","xRez=500; yRez=300; COLOR_CHANNELS=3  # black background dimensions\n","x0=10; y0=10;   # location of box in background\n","\n","# For changing color of rect\n","chanB = 0; chanG = 1; chanR = 2    # BGR Channel Index\n","\n","# create black background\n","displayBlackIM=np.zeros((yRez,xRez,COLOR_CHANNELS),dtype='uint8') # black display\n","\n","# Make copy of black background image\n","displayIM=displayBlackIM.copy()\n","\n","# Create box\n","rectX = 100\n","rectY = 100\n","rect = np.zeros((rectY, rectX, COLOR_CHANNELS), dtype='uint8') # black box\n","\n","# Make Box White\n","# rect[:, :, :] = 255\n","\n","#rect[:, :, chanB] = 255 # Make Box Blue\n","rect[:, :, chanG] = 255 # Make Box Green\n","#rect[:, :, chanR] = 255 # Make Box Red\n","\n","# insert sprite into background at location x0, y0\n","displayIM[y0:y0+rectY,x0:x0+rectX,:] = rect  # paste box into black display\n","\n","cv2_imshow(displayIM)\n","\n","cv2.destroyAllWindows()\n"],"metadata":{"id":"-X1ZWp1rXWc7","colab":{"base_uri":"https://localhost:8080/","height":317},"executionInfo":{"status":"ok","timestamp":1654733779223,"user_tz":420,"elapsed":297,"user":{"displayName":"John Duong","userId":"17043314397277925368"}},"outputId":"ef748204-8bd9-4e2a-c248-091c90f0ea36"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=500x300 at 0x7FE5F3C27BD0>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfQAAAEsCAIAAAC62dafAAACrUlEQVR4nO3UsQnAMBAEQVn992yXIGSMDMtM+snxwY4BAAAAAAAAAAAAAAAAAAA7rsX9PrKiYfVLgGPm3wMA+J64AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJOwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC88gC/eAHIpHOXzAAAAABJRU5ErkJggg==\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Single Bouncing Box Movie\n","Step 1 complete. We have a static image. A video or movie is just a series of images (called \"frames\"), so we're going to create this movie first. then I'll show you how to create two moving boxes.\n","\n","We will be using modified code the bouncing sprite animation from a previous lesson."],"metadata":{"id":"-095uAW8Fey9"}},{"cell_type":"code","source":["# Bouncing Box\n","\n","CYCLES=20 # number of times to move box, aka number of frames\n","\n","xRez=500; yRez=300; COLOR_CHANNELS=3  # black background dimensions\n","\n","# For changing color of rectangle\n","chanB = 0; chanG = 1; chanR = 2    # BGR Channel Index\n","\n","# starting location and movement direction\n","x0=10; y0=10; # ball starting position (close to top-left of background)\n","stepSize=20 # how many pixels to move box in each frame\n","# amount of pixels to move in x and y direction using stepSize\n","moveX=stepSize; moveY=stepSize\n","\n","# Create box, using similar variables as a previous lesson.\n","rectX = 100 # Width of box\n","rectY = 100 # Height of box\n","rect = np.zeros((rectY, rectX, COLOR_CHANNELS), dtype='uint8') # black box\n","rect[:, :, chanG] = 255 # Make Box Green\n","# Note: play around with different valuse to get different colors.\n","\n","for i in range(CYCLES):    \n","    # increment moveX and moveY to move the box\n","    x0+=moveX \n","    y0+=moveY\n","   \n","    # Boundary Detection\n","    # Summary: If hitting the boundary, go in the opposite direction\n","    if x0 < 0:\n","        # If hitting the left boundary, make the box move right,\n","        # and reset x0 to zero so it doesn't leave the background\n","        moveX = stepSize # make the increment positive\n","        x0 = 0\n","    if y0 < 0:\n","        # If hitting the top boundary, make box go down\n","        # and reset y0 so it doesn't leave the boundary\n","        moveY = stepSize  # make the increment positive\n","        y0 = 0\n","    if x0 + rectX >= xRez:\n","        # If hitting right boundary, make box go left\n","        # and make sure right side of box is a little left of boundary\n","        # you will get a index out of bounds error\n","        # (Python usually doesn't include the end value)\n","        moveX = -stepSize  # make the increment negative\n","        x0 = xRez - rectX - 1\n","    if y0 + rectY >= yRez:\n","       # Same as the above, except for the bottom boundary.\n","        moveY = -stepSize  # make the increment negative\n","        y0 = yRez - rectY - 1\n","\n","    # move image\n","    displayIM=np.zeros((yRez,xRez,COLOR_CHANNELS),dtype='uint8') # black display\n","    displayIM[y0:y0+rectY,x0:x0+rectX,:] = rect  # paste rect/box image into black display\n","    cv2_imshow(displayIM)\n","    sleep(.5) # delay so we can see the image (in seconds)\n","    display.clear_output(wait=True)\n","   \n","print(\"Reached end of animation\")\n","\n","cv2.destroyAllWindows()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":536},"id":"VahRcOPWd1Bq","executionInfo":{"status":"error","timestamp":1654742958593,"user_tz":420,"elapsed":2208,"user":{"displayName":"John Duong","userId":"17043314397277925368"}},"outputId":"fa9bced8-e852-4e2a-80dd-5b765edbe97f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=500x300 at 0x7FE602C03C50>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfQAAAEsCAIAAAC62dafAAACq0lEQVR4nO3UwQ2AMBAEsUD/PUMTkBODXcE+VrMWAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA8E/H9ICQa3rAh/gdvOycHgDA88QdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAYLEHSBI3AGCxB0gSNwBgsQdIEjcAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtroBOw8ByFp0L0MAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-6f3476ef22f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mdisplayIM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrectY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrectX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrect\u001b[0m  \u001b[0;31m# paste rect/box image into black display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mcv2_imshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplayIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# delay so we can see the image (in seconds)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Double Bouncing Box Movie\n","We now have a singular moving box movie! One step close to having intersecting boxes to see how OpenCV \"sees\" it.\n","\n","To test if the boundary detection is working, increase the number of cycles or size of the box until you the box hit all 4 boundaries (left, top, right, bottom).\n","\n","To develop your programming intuition, here are some things you can do:\n","\n","* play around with different width and height values of the box\n","* comment the line \"x0 = 0\" to see what happens (make a prediction before you do to test your understanding)\n","* remove a \"- 1\" from \"y0 = yRez - rectY - 1\" to see what happens.\n","* Try to get a specific color, use a website like this to help pick a color:\n","https://www.rapidtables.com/web/color/RGB_Color.html . Even though it says RGB, you only have to input the correct values for the correct channel. So if R is 255, you have to make the box's red channel (chanR) to 255.\n","\n","Now, let's create two bouncing boxes that intersect. Overall, you will have to duplicate certain code chunks to have individual contorl of each box. With this code, we will also save the \"movie\" into a list (recall that a movie is series of images)"],"metadata":{"id":"8NyTBJVVXcWk"}},{"cell_type":"code","source":["# Two Bouncing Boxes Movie\n","\n","CYCLES=20 # number of times to move box\n","\n","xRez=500; yRez=300; COLOR_CHANNELS=3  # black background dimensions\n","# Box Color Channels, as BGR Indices\n","chanB = 0; chanG = 1; chanR = 2    # BGR Channel Index\n","\n","# Pixel Amount for box to move (idea: make it individual to each box)\n","stepSize=20\n","\n","# Create box 1\n","# Note to content creators: should we use W (width) instead of x?\n","box1X = 100; box1Y = 100    # Box width (x) and height (y)\n","box1 = np.zeros((box1Y, box1X, COLOR_CHANNELS), dtype='uint8') # black box\n","box1[:, :, chanG] = 255 # Make Box Green\n","\n","# Create box 2\n","box2X = 100; box2Y = 10\n","box2 = np.zeros((box2Y, box2X, COLOR_CHANNELS), dtype='uint8') # black box\n","box2[:, :, chanB] = 255 # Make Box Blue\n","\n","\n","# starting location and movement direction section\n","# Box 1\n","box1_x0=10; box1_y0=10; # box 1 starting position\n","box1_moveX=stepSize; box1_moveY=stepSize\n","\n","# Box 2\n","rMargin = 100 # how much empty space to leave on the right side of the box\n","# box 2 starting position, opposite of box 1\n","box2_x0 = xRez - (box2X + rMargin)\n","box2_y0 = 10;\n","box2_moveX=-stepSize; box2_moveY=stepSize\n","\n","# Note: why is box2_x0 = xRez - (box2X + rMargin)?\n","# Answer: Because I did not want the box to accidentally cross the boundary and cause a crash\n","\n","# Initialize image_list, this will hold the \"movie\"\n","image_list = []\n","\n","for i in range(CYCLES):\n","\n","    # increment box1 moveX and moveY to move the box\n","    box1_x0+=box1_moveX \n","    box1_y0+=box1_moveY\n","\n","    # increment box2 moveX and moveY to move the box\n","    box2_x0+=box2_moveX \n","    box2_y0+=box2_moveY\n","\n","    # Normal Box 1 Border Movement\n","    if box1_x0 < 0:\n","        box1_moveX = stepSize # make the increment positive\n","        box1_x0=0\n","    if box1_y0<0:\n","        box1_moveY = stepSize  # make the increment positive\n","        box1_y0=0\n","    if box1_x0+box1X>=xRez:\n","        box1_moveX = -stepSize  # make the increment negative\n","        box1_x0=xRez-box1X-1\n","    if box1_y0+box1Y>=yRez:\n","        box1_moveY = -stepSize  # make the increment negative\n","        box1_y0=yRez-box1Y-1\n","    \n","    # Normal Box 2 Border Movement\n","    if box2_x0 < 0:\n","        box2_moveX = stepSize # make the increment positive\n","        box2_x0=0\n","    if box2_y0<0:\n","        box2_moveY = stepSize  # make the increment positive\n","        box2_y0=0\n","    if box2_x0+box2X>=xRez:\n","        box2_moveX = -stepSize  # make the increment negative\n","        box2_x0=xRez-box1X-1\n","    if box2_y0+box2Y>=yRez:\n","        box2_moveY = -stepSize  # make the increment negative\n","        box2_y0=yRez-box2Y-1\n","\n","    # move image\n","\n","    # Create Background\n","    displayIM=np.zeros((yRez,xRez,COLOR_CHANNELS),dtype='uint8') # black display\n","    \n","    # Add Box 1 to Black Display\n","    displayIM[box1_y0:box1_y0+box1Y,box1_x0:box1_x0+box1X,:] = box1  # paste sprite image into black display\n","\n","    # Add Box 2 to Black Display\n","    displayIM[box2_y0:box2_y0+box2Y,box2_x0:box2_x0+box2X,:] = box2  # paste sprite image into black display\n","\n","    # Working Display Code, commented so images are quickly saved.\n","    # cv2_imshow(displayIM)\n","    # sleep(.5) # delay so we can see the image (in seconds)\n","    # display.clear_output(wait=True)\n","\n","    # Make a copy, very important!\n","    # Otherwise you end up with a movie of the same image\n","    frame = displayIM.copy()\n","\n","    # Uncomment the next 3 lines to see if frame copying worked\n","    # cv2_imshow(frame)\n","    # sleep(.5) # delay so we can see the image (in seconds)\n","    # display.clear_output(wait=True)\n","\n","    # Append to image_list\n","    image_list.append(frame)\n","   \n","print(f\"len of image_list: {len(image_list)}\") # Should match number of cycles\n","print(f\"Number of cycles: {CYCLES}\")\n","\n","print(\"Reached end of animation\")\n","\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fzBs_0oxwUfa","executionInfo":{"status":"ok","timestamp":1654817160932,"user_tz":420,"elapsed":257,"user":{"displayName":"John Duong","userId":"17043314397277925368"}},"outputId":"77b7ec2e-d89e-4c60-a873-ddd8fcde366f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["len of image_list: 20\n","Number of cycles: 20\n","Reached end of animation\n"]}]},{"cell_type":"markdown","source":["## Movie Playback, Two Methods\n","\n","Notice how 20 images were saved in the image_list variable. You can uncomment cv_imshow() chunks to make sure the images are displayed correctly. However, we want to see if frames were saved correctly into the image_list variable. So I will show you two ways to do that. First, we're going to use a for loop to iterate (go step-by-step) through each image and display."],"metadata":{"id":"L0LqffAwba1T"}},{"cell_type":"code","source":["# Method 1 of iterating through \"movie\" using for list for loop (Works!)\n","\n","for image in image_list:\n","  cv2_imshow(image)\n","  sleep(.5) # delay so we can see the image (in seconds)\n","  display.clear_output(wait=True)\n","\n","print(\"Reached end of animation\")\n","\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"9AYksZ1Bb-UW","executionInfo":{"status":"ok","timestamp":1654817178608,"user_tz":420,"elapsed":10606,"user":{"displayName":"John Duong","userId":"17043314397277925368"}},"outputId":"e1b7e06e-f4d4-4cf8-e918-7fdcc447ec48"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reached end of animation\n"]}]},{"cell_type":"markdown","source":["Did it play correctly? If it did, then it worked! If it didn't, time to go back to the code chunk where the movie was first created and display the image as it loops initially.\n","\n","Next is the second method of video playback. We'll have to convert the list into a numpy 4D array, then iterate using range() in the for loop."],"metadata":{"id":"gPnxxUGecOJs"}},{"cell_type":"code","source":["# Method 2 of iterating through numpy 4D array \"movie\" (Works!)\n","\n","# Create numpy array from list of images\n","new_arr = np.array(image_list)\n","print(f\"new_arr.shape: {new_arr.shape}\")\n","# Notice how the first axis has the number of cycles (e.g. 20).\n","# Interesting coincidence. We're going to use that to loop.\n","\n","# Iterate through 4D numpy array using index\n","for i in range(CYCLES):\n","  image = new_arr[i, :, :, :]\n","\n","  # print(f\"image shape: {image.shape}\") # Make sure the image has the right dimensions.\n","  cv2_imshow(image)\n","  sleep(.5) # delay so we can see the image (in seconds)\n","  display.clear_output(wait=True)\n","  \n","print(\"Reached end of animation\")\n","\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"eDcUSIF8c1Ss","executionInfo":{"status":"ok","timestamp":1654744627527,"user_tz":420,"elapsed":9385,"user":{"displayName":"John Duong","userId":"17043314397277925368"}},"outputId":"9b7c8273-0fa6-44c7-d46f-098869d09337"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reached end of animation\n"]}]},{"cell_type":"markdown","source":["Wait, so why bother learning both methods? For memory reasons. In Python, lists tend to take up more memory than numpy arrays. If we're doing 20 images, it might not be a problem. But imagine doing a million images, you will eventually cause a memory leak on your computer, potentially crashing your computer, and potentially losing hours or days of work. If you have ever written a 10-page paper for months, and a sudden computer crashed caused it to disappear, then you know the feeling all too well.\n","\n","However, we're using Google CoLab (cloud computing with large memory) and using a small amount of images, so it's not a problem for now. It's something to keep in mind when you're handling large datasets.\n","\n","Additionally, both methods employ programming techniques you will need in your future. Method 2 uses a number (variable i), to access the image. We'll be using that in the very near future.\n","\n","In summary, you learned how to create a video to two intersecting boxes and learned how to save those videos to a list of images, then learned how play back that video.\n","\n","For the next section, we're going to detect the two moving boxes using OpenCV. Before, you've done it on a static image, now let's do it on a movie.\n","\n","---"],"metadata":{"id":"TLIdOi4ObVuS"}},{"cell_type":"markdown","source":["# Task 2: Detect Code on Two Moving Boxes Movie\n","\n","Learning Outcomes:\n","* Run the object detection code on your own movie.\n","* Learn some limitations of OpenCV\n","* Be ready for real world video and tracking."],"metadata":{"id":"0d4dCqQJ6dJ2"}},{"cell_type":"markdown","source":["Excellent work so far, the work you've done so far is equivalent to a few weeks of work in an introductory programming class for computer science majors, except we provide biology examples!\n","\n","Now that you created a sample video (e.g. a series of images) of intersecting boxes, let's find out how OpenCV sees it. A human, you, will see two separate boxes. What do you think OpenCV will see?\n","\n","Recall that the detection pipeline looks something like this:\n","\n","image -> convert to gray scale -> convert to binary image -> detect objects in binary image -> display results in original image. It sounds complicated on first viewing, but you've done this before with a static image, so let's do this on a series of images instead.\n"],"metadata":{"id":"Xmtefm-xzT6T"}},{"cell_type":"markdown","source":["## Convert Movie to Grayscale\n","\n","First, let's convert that series of images into grayscale."],"metadata":{"id":"6T0FDWr1r_fX"}},{"cell_type":"code","source":["# Convert image list to grayscale\n","\n","# Initialize empty gray_image_list\n","gray_image_list = []\n","\n","# Use for loop to go through each image in image list\n","for image in image_list:\n","  # Convert image to grayscale\n","  grayIM = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","  # cv2_imshow(grayIM)\n","  # sleep(.5) # delay so we can see the image (in seconds)\n","  # display.clear_output(wait=True)\n","\n","  # Append to gray_image_list\n","  gray_image_list.append(grayIM)\n","  \n","\n","# \"play\" grayscale image list to see if it worked\n","\n","for grayIMG in gray_image_list:\n","  cv2_imshow(grayIMG)\n","  sleep(.5) # delay so we can see the image (in seconds)\n","  display.clear_output(wait=True)\n","\n","print(\"Reached end of animation\")\n","\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"iZavnF066cwO","executionInfo":{"status":"ok","timestamp":1654822105199,"user_tz":420,"elapsed":10367,"user":{"displayName":"John Duong","userId":"17043314397277925368"}},"outputId":"4fa19247-5a38-4c5e-e57b-2a5a25c718c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reached end of animation\n"]}]},{"cell_type":"markdown","source":["## Grayscale to Binary Conversion\n","Was the video in grayscale? If it is, then it worked. Now let's turn all images into a series of binary images. You will have to play with the thresh value to get both boxes to show up.\n","\n","Recall that thresh stands for the threshold to determine if a pixel is turned into black (0) or white (255). So if your thresh is 25 and if the pixel value is below 25, it will be turned into a zero; and if above, it is maxed to 255 (white).\n","\n","Using the box example, if the box is too dark (or heading towards zero), then your thresh value needs to be low enough that the box is turned white instead."],"metadata":{"id":"bHZBvguc-aXE"}},{"cell_type":"code","source":["# Convert gray scale image list to binary\n","\n","thresh = 25 # used to determine if a pixel is assigned 0 or 255\n","max_val = 255 # used to determine what maximum value anything above thresh should become\n","\n","# Initialize empty binary_image_list\n","binary_image_list = []\n","\n","for grayIMG in gray_image_list:\n","\n","  ret, binaryIM = cv2.threshold(grayIMG, thresh, max_val, cv2.THRESH_BINARY) # threshold output shown as white\n","\n","  # cv2_imshow(binaryIM)\n","  # sleep(.5) # delay so we can see the image (in seconds)\n","  # display.clear_output(wait=True)\n","\n","  # Append to binary_image_list\n","  binary_image_list.append(binaryIM)\n","\n","# \"play\" binary image list to see if it worked\n","\n","for binaryIMG in binary_image_list:\n","  cv2_imshow(binaryIMG)\n","  sleep(.5) # delay so we can see the image (in seconds)\n","  display.clear_output(wait=True)\n","\n","print(\"Reached end of animation\")\n","\n","cv2.destroyAllWindows()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"gBXocXF-N0GI","executionInfo":{"status":"ok","timestamp":1654822118344,"user_tz":420,"elapsed":10362,"user":{"displayName":"John Duong","userId":"17043314397277925368"}},"outputId":"a2973a78-6978-4263-d525-87b605b7a0cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reached end of animation\n"]}]},{"cell_type":"markdown","source":["## Find Contours of Binary Movie\n","You should get two white boxes moving around on a black background. If that didn't happen, increase or decrease the thresh variable; it has a range of 0 to 255. Try going up or down by 50 (e.g. 0, 50, 100) to see when boxes disappear or reappear. Once you find that, try smaller values to find that sweet spot; for example, let's say 50 work, try 60 or 40, and see what happens. This will help develop your intuition for thresholding.\n","\n","Now that we have a binary series of images, let's detect the objects. Remember, OpenCV considers white things as objects. It's similar to squinting your eyes at a real life object until the details vanish, then all you're left with is the object itself. How many objects do you think OpenCV will detect when the boxes intersect? None, one, or two?"],"metadata":{"id":"Luf5TX2lB6ja"}},{"cell_type":"code","source":["# Find Contours of each binary image\n","\n","# Border Constants (placed here for easier control)\n","# border_color = 125 # For grayscale, value between 0 and 255. 125 is gray.\n","border_color = (0, 255, 255) # For BGR, value between 0 and 255. Yellow\n","thick = 2   # thickness of rectangle lines around detected objects\n","\n","# Make a deep copy of Image List since we will draw the contours on it.\n","# Why \"deepcopy()\" instead of just \"copy()\"? While copy works for numpy,\n","# copy() still only references the original list, so our code will\n","# actually tamper with the original image, messing up future algorithms.\n","# A deepcopy will make duplicates of everything in the list.\n","# For more details, check out this link:\n","#  https://www.geeksforgeeks.org/copy-python-deep-copy-shallow-copy/\n","image_list_edit = copy.deepcopy(image_list)\n","\n","# Use a for loop with \"i\" instead, so that they match with the original image_list.\n","# For example, index 0 in the binary_image_list will have the corresponding\n","# original image at the same index. This makes adding the contour much easier.\n","for i in range(len(binary_image_list)):\n","\n","  # Get the Binary Image from the list\n","  binaryIMG = binary_image_list[i]\n","  origIM = image_list_edit[i]\n","\n","  contourList, hierarchy = cv2.findContours(binaryIMG, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # all countour points, uses more memory\n","  \n","  for objContour in contourList:\n","    # Create a bounding rectangle using the objContour points, store in a list called PO (Points of Object)\n","    PO = cv2.boundingRect(objContour)\n","\n","    # Extract the values from PO\n","    # PO list order: x-origin, y-origin, rectangle width, and rectangle height\n","    # Origin is the top-left of the rectangle\n","    x0=PO[0]; y0=PO[1]; w=PO[2]; h=PO[3]\n","\n","    # Optional: print out the results to see how different they are (uncomment the below line)\n","    # print(f\"x0: {x0}, y0: {y0}, w: {w}, h: {h}\")\n","\n","    # Draw the rectangle on origIM starting at the top-left at (x0,y0) and\n","    # ending at the bottom right (x0+w,y0+h).\n","    # Use the gray border_color with a thickness of 3 pixels.\n","    cv2.rectangle(origIM, (x0,y0), (x0+w,y0+h), border_color, thick)\n","    \n","  # Print out how many objects OpenCV sees.\n","  # What happens when the boxes intersect? Will there be 0, 1, or 2 objects counted?\n","  print(f\"Object count = {len(contourList)}\")\n","  cv2_imshow(origIM)\n","\n","  sleep(.5) # delay so we can see the image (in seconds)\n","  display.clear_output(wait=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"id":"_cEUhA8EOtIZ","executionInfo":{"status":"ok","timestamp":1654822517105,"user_tz":420,"elapsed":10486,"user":{"displayName":"John Duong","userId":"17043314397277925368"}},"outputId":"1f6709d8-6219-493d-c0d8-f0cfeee01de9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Object count = 2\n"]},{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=500x300 at 0x7F575EBFBED0>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAfQAAAEsCAIAAAC62dafAAADC0lEQVR4nO3cQWrDQBBFwYzR/a88WYSsgyC4PU9VJ/gI82gb4fUF8PH2nl5wmtf0AAD+3zU9AOCGNT3g8/18yXG5AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QJC4AwSJO0CQuAMEiTtAkLgDBIk7QNA1PQDghj094BQud4AgcQcOsNb0AgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgHOs6QHvtvf0gqOsx31AIOI1PeCtlP0uTwwO9ay4AzzENT1gxlou0j/s7RcZOJjLHSBI3AGCxB0gSNwBgsQdIEjcAYIe+iqk9/yANpc7QNCz4u6fUu7yxAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgF/ffrQP632R/PcAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"markdown","source":["If you guessed 1 object would be detected when the boxes intersect, then you got it right! Regardless, why is that? What happened? As you saw in the binary video, both boxes actually combined to create something new, almost like a crane made from legos or something.\n","\n","And will this cause a problem when studying something like moving plankton? Yes, it will. This is an example where programming can help with automating certain tasks, but may present more programming challenges to overcome.\n","\n","Additionally, it demostrates how powerful our human minds are if computers have difficulty achieving what our brains do in a fraction of a second.\n","\n"],"metadata":{"id":"xHn9FOF6FhXf"}},{"cell_type":"markdown","source":["## Conclusion\n","\n","For this lesson, you applied what you learned for static images and applied it to a movie you created, and saw what happens when two different objects crossed paths. Later on, you will use the skills here on actual video footage of plankton moving around."],"metadata":{"id":"47LsyQ8Cr4xn"}}]}